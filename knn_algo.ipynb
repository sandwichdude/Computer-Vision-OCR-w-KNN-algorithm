{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "817a1287-f240-4349-9711-200da481f71e",
   "metadata": {},
   "source": [
    "Importing Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65bb3634-94df-4cce-ac01-f58a1adf01b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import codecs\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6f9f6d-6960-473b-8f9b-8f4c0deb2aef",
   "metadata": {},
   "source": [
    "Loading the Images and the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f74c8d14-514e-40a7-b184-c88a941e1fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = 'C:/Users/DELL/OneDrive - City University of Hong Kong - Student/Desktop/OpenCV/MNIST_Data/'\n",
    "def load():\n",
    "    sets = ['train', 'test']\n",
    "    data_dict = {}\n",
    "    for set in sets:\n",
    "        images = []\n",
    "        labels = []\n",
    "        for i in range(10):\n",
    "            # READ ALL THE IMAGES IN THE FOLDER\n",
    "            for file in os.listdir(datapath+set+'/'+str(i)):\n",
    "                image = cv.imread(datapath+set+'/'+str(i)+'/'+file, 0)\n",
    "                image = image.astype('float32')\n",
    "                images.append(image)\n",
    "                labels.append(i)\n",
    "        # SAVE THE IMAGES AND LABELS TO A CORRESPONDING KEY\n",
    "        data_dict[set+'_images'] = np.array(images)\n",
    "        data_dict[set+'_labels'] = np.array(labels)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c07c64-939b-429b-965b-669ba702ec97",
   "metadata": {},
   "source": [
    "Displaying an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e4ce287-364a-4f13-94d2-f993b4b074fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display():\n",
    "    data_dict = load()\n",
    "    images = data_dict['train_images']\n",
    "    labels = data_dict['train_labels']\n",
    "    no_of_samples = images.shape[0]\n",
    "    for i in range(10):\n",
    "        # RANDOMLY SELECT A SAMPLE\n",
    "        index = np.random.randint(0, no_of_samples)\n",
    "        image = images[index]\n",
    "        label = labels[index]\n",
    "        # DISPLAY THE IMAGE AND LABEL\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.title('Label: '+str(label))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2dcb7f-e05a-47eb-979a-4f894f5347c6",
   "metadata": {},
   "source": [
    "Reshape the images to 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a4e438e-5b8a-4e07-bb87-6ee3a99c10fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape():\n",
    "    sets = ['train', 'test']\n",
    "    data_dict = load()\n",
    "    for set in sets:\n",
    "        images = data_dict[set+'_images']\n",
    "        no_of_samples = images.shape[0]\n",
    "        # RESHAPE THE IMAGES TO [NO_OF_SAMPLES x HEIGHT*WIDTH]\n",
    "        data_dict[set+'_images'] = images.reshape(no_of_samples, -1)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc79d8a-ca67-4993-b521-92a6a0ddc228",
   "metadata": {},
   "source": [
    "Normalizing the pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87cc479c-0436-4c00-8511-fd3ff7b68186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize():\n",
    "    sets = ['train', 'test']\n",
    "    data_dict = reshape()\n",
    "    for set in sets:\n",
    "        images = data_dict[set+'_images']\n",
    "        # NORMALIZE THE PIXEL VALUES TO [0, 1]\n",
    "        data_dict[set+'_images'] = images/255\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c801218-8ad5-4aa3-85e0-7a5ca9c04b55",
   "metadata": {},
   "source": [
    "Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0b13e13-ba3e-4b1f-82d6-0543f3b30fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    data_dict = normalize()\n",
    "    train_images = data_dict['train_images']\n",
    "    train_labels = data_dict['train_labels']\n",
    "    # CREATE THE MODEL\n",
    "    model = KNeighborsClassifier(n_neighbors=5)\n",
    "    # TRAIN THE MODEL\n",
    "    model.fit(train_images, train_labels)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a875516-8a49-48ea-a9ca-8e60c467cfbd",
   "metadata": {},
   "source": [
    "Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0365800-163e-49c3-a29e-e4076a69c0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    data_dict = normalize()\n",
    "    test_images = data_dict['test_images']\n",
    "    test_labels = data_dict['test_labels']\n",
    "    # LOAD THE TRAINED MODEL\n",
    "    model = train()\n",
    "    # PREDICT THE LABELS\n",
    "    predicted_labels = model.predict(test_images)\n",
    "    # CALCULATE THE ACCURACY\n",
    "    accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "    print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56de1d1e-f042-4cfd-a5b6-568084e2009f",
   "metadata": {},
   "source": [
    "Predict the Label of a Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0806091-87e5-4bb2-a5ad-57466b00c919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    data_dict = normalize()\n",
    "    train_images = data_dict['train_images']\n",
    "    train_labels = data_dict['train_labels']\n",
    "    # LOAD THE TRAINED MODEL\n",
    "    model = train()\n",
    "    # READ THE IMAGE\n",
    "    image = cv.imread('image.jpg', 0)\n",
    "    # RESHAPE THE IMAGE TO [1 x HEIGHT*WIDTH]\n",
    "    image = image.reshape(1, -1)\n",
    "    # NORMALIZE THE PIXEL VALUES TO [0, 1]\n",
    "    image = image/255\n",
    "    # PREDICT THE LABEL\n",
    "    predicted_label = model.predict(image)\n",
    "    print('Predicted Label: ', predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87616d52-591b-49ad-af62-3ea38235c6cc",
   "metadata": {},
   "source": [
    "Main Method to Call functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7642e11-fe8a-4c96-b529-45dbd6a074e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m     test()\n\u001b[0;32m      5\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m----> 6\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmain\u001b[39m():\n\u001b[1;32m----> 2\u001b[0m     display()\n\u001b[0;32m      3\u001b[0m     test()\n",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m, in \u001b[0;36mdisplay\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdisplay\u001b[39m():\n\u001b[1;32m----> 2\u001b[0m     data_dict \u001b[39m=\u001b[39m load()\n\u001b[0;32m      3\u001b[0m     images \u001b[39m=\u001b[39m data_dict[\u001b[39m'\u001b[39m\u001b[39mtrain_images\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m     labels \u001b[39m=\u001b[39m data_dict[\u001b[39m'\u001b[39m\u001b[39mtrain_labels\u001b[39m\u001b[39m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[2], line 12\u001b[0m, in \u001b[0;36mload\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(datapath\u001b[39m+\u001b[39m\u001b[39mset\u001b[39m\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(i)):\n\u001b[0;32m     11\u001b[0m     image \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mimread(datapath\u001b[39m+\u001b[39m\u001b[39mset\u001b[39m\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(i)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mfile, \u001b[39m0\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m     image \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39;49mastype(\u001b[39m'\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m     images\u001b[39m.\u001b[39mappend(image)\n\u001b[0;32m     14\u001b[0m     labels\u001b[39m.\u001b[39mappend(i)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    display()\n",
    "    test()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b91f41160b83ffc59c7e17fa6fd02d637d5dcf1d5e59aa2db87d82178661b954"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
